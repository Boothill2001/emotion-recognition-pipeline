{"cells":[{"cell_type":"markdown","id":"5d1cd39d","metadata":{"id":"5d1cd39d"},"source":["# 🧠 07 - Feature Extraction with ResNet50\n","\n","This notebook performs high-level feature extraction from real-world facial images using a pretrained **ResNet50** model.  \n","Each image is transformed into a **2048-dimensional feature vector**, capturing key visual patterns such as facial structure, emotion cues, and textures.\n","\n","These image embeddings will serve as the input for downstream tasks like:\n","\n","- 🎯 Emotion classification modeling\n","- 📊 Clustering / t-SNE visualization\n","- 🧠 Model explainability using SHAP\n","\n","By leveraging a powerful transfer learning backbone (ResNet50 pretrained on ImageNet), we significantly reduce the need for custom feature engineering and enable fast, scalable training for real-world applications.\n"]},{"cell_type":"code","execution_count":1,"id":"92bdbb88","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92bdbb88","executionInfo":{"status":"ok","timestamp":1742811537941,"user_tz":-420,"elapsed":17668,"user":{"displayName":"Trí Minh Nguyễn","userId":"13730675261346438318"}},"outputId":"a0f5ac9d-fb98-4981-cf23-636f20446bfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Downloaded final dataset from GCS → /content/final_emotion_dataset.parquet\n"]}],"source":["\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","from google.cloud import storage\n","import pandas as pd\n","import os\n","\n","# GCS Config\n","project_id = 'exalted-summer-454012-d2'\n","bucket_name = 'boothill2001-dataset'\n","source_path = 'dataset/final_emotion_dataset.parquet'\n","local_parquet_path = '/content/final_emotion_dataset.parquet'\n","\n","# Download from GCS\n","client = storage.Client(project=project_id)\n","bucket = client.bucket(bucket_name)\n","blob = bucket.blob(source_path)\n","blob.download_to_filename(local_parquet_path)\n","\n","print(f\"✅ Downloaded final dataset from GCS → {local_parquet_path}\")\n"]},{"cell_type":"code","execution_count":2,"id":"06d41c37","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"06d41c37","executionInfo":{"status":"ok","timestamp":1742811544921,"user_tz":-420,"elapsed":602,"user":{"displayName":"Trí Minh Nguyễn","userId":"13730675261346438318"}},"outputId":"8af1befe-10cb-45f7-eb17-532e52b539ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Loaded 31783 samples\n"]},{"output_type":"execute_result","data":{"text/plain":["         filename  age                                             gender  \\\n","0  1000092795.jpg   31  {'Woman': np.float32(8.204366), 'Man': np.floa...   \n","1    10002456.jpg   30  {'Woman': np.float32(2.7630906), 'Man': np.flo...   \n","2  1000268201.jpg   29  {'Woman': np.float32(4.2036314), 'Man': np.flo...   \n","3  1000344755.jpg   33  {'Woman': np.float32(8.685013), 'Man': np.floa...   \n","4  1000366164.jpg   41  {'Woman': np.float32(0.96645916), 'Man': np.fl...   \n","\n","  dominant_emotion dominant_race  \n","0          neutral         asian  \n","1          neutral         white  \n","2              sad         white  \n","3             fear         white  \n","4             fear         white  "],"text/html":["\n","  <div id=\"df-130ecbb7-2866-42c5-b8fa-894670e40135\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>dominant_emotion</th>\n","      <th>dominant_race</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000092795.jpg</td>\n","      <td>31</td>\n","      <td>{'Woman': np.float32(8.204366), 'Man': np.floa...</td>\n","      <td>neutral</td>\n","      <td>asian</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10002456.jpg</td>\n","      <td>30</td>\n","      <td>{'Woman': np.float32(2.7630906), 'Man': np.flo...</td>\n","      <td>neutral</td>\n","      <td>white</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000268201.jpg</td>\n","      <td>29</td>\n","      <td>{'Woman': np.float32(4.2036314), 'Man': np.flo...</td>\n","      <td>sad</td>\n","      <td>white</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000344755.jpg</td>\n","      <td>33</td>\n","      <td>{'Woman': np.float32(8.685013), 'Man': np.floa...</td>\n","      <td>fear</td>\n","      <td>white</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000366164.jpg</td>\n","      <td>41</td>\n","      <td>{'Woman': np.float32(0.96645916), 'Man': np.fl...</td>\n","      <td>fear</td>\n","      <td>white</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-130ecbb7-2866-42c5-b8fa-894670e40135')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-130ecbb7-2866-42c5-b8fa-894670e40135 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-130ecbb7-2866-42c5-b8fa-894670e40135');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a3b28603-522d-4b81-ab50-66be2356624f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3b28603-522d-4b81-ab50-66be2356624f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a3b28603-522d-4b81-ab50-66be2356624f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 31783,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31783,\n        \"samples\": [\n          \"4758571023.jpg\",\n          \"2667549961.jpg\",\n          \"582899605.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 12,\n        \"max\": 60,\n        \"num_unique_values\": 44,\n        \"samples\": [\n          13,\n          40,\n          46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31743,\n        \"samples\": [\n          \"{'Woman': np.float32(3.119665), 'Man': np.float32(96.88034)}\",\n          \"{'Woman': np.float32(7.9119697), 'Man': np.float32(92.08803)}\",\n          \"{'Woman': np.float32(4.8258533), 'Man': np.float32(95.17414)}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dominant_emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"neutral\",\n          \"sad\",\n          \"surprise\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dominant_race\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"asian\",\n          \"white\",\n          \"indian\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":2}],"source":["\n","df = pd.read_parquet(\"/content/final_emotion_dataset.parquet\")\n","print(f\"✅ Loaded {len(df)} samples\")\n","df.head()\n"]},{"cell_type":"code","execution_count":3,"id":"16412f1b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16412f1b","executionInfo":{"status":"ok","timestamp":1742811569913,"user_tz":-420,"elapsed":9553,"user":{"displayName":"Trí Minh Nguyễn","userId":"13730675261346438318"}},"outputId":"38a1f326-4989-469e-c2a3-cc2da76d4da8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","✅ ResNet50 model loaded.\n"]}],"source":["\n","import numpy as np\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Model\n","from tqdm import tqdm\n","import PIL\n","import io\n","\n","# Load ResNet50\n","base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n","model = Model(inputs=base_model.input, outputs=base_model.output)\n","\n","print(\"✅ ResNet50 model loaded.\")\n"]},{"cell_type":"code","execution_count":4,"id":"a70cc54a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a70cc54a","executionInfo":{"status":"ok","timestamp":1742812354195,"user_tz":-420,"elapsed":770260,"user":{"displayName":"Trí Minh Nguyễn","userId":"13730675261346438318"}},"outputId":"5350dd94-24eb-418d-93c5-dcc88cffa767"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 31783/31783 [12:50<00:00, 41.26it/s]"]},{"output_type":"stream","name":"stdout","text":["✅ Extracted features for 0 images. Errors: 31783\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["\n","def load_and_preprocess_from_gcs(gcs_path, bucket):\n","    blob = bucket.blob(gcs_path)\n","    img_data = blob.download_as_bytes()\n","    img = PIL.Image.open(io.BytesIO(img_data)).resize((224, 224)).convert(\"RGB\")\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    return preprocess_input(x)\n","\n","features = []\n","errors = []\n","\n","for idx, row in tqdm(df.iterrows(), total=len(df)):\n","    try:\n","        x = load_and_preprocess_from_gcs(row['filename'], bucket)\n","        feat = model.predict(x, verbose=0).flatten()\n","        features.append(feat)\n","    except Exception as e:\n","        errors.append((row['filename'], str(e)))\n","\n","print(f\"✅ Extracted features for {len(features)} images. Errors: {len(errors)}\")\n"]},{"cell_type":"code","execution_count":5,"id":"b490c440","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b490c440","executionInfo":{"status":"ok","timestamp":1742812354348,"user_tz":-420,"elapsed":14,"user":{"displayName":"Trí Minh Nguyễn","userId":"13730675261346438318"}},"outputId":"e32ee331-1db2-463a-e257-0fd5ad3adff1"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Saved extracted features to image_vectors.npy\n"]}],"source":["\n","features_array = np.array(features)\n","np.save(\"/content/image_vectors.npy\", features_array)\n","print(\"✅ Saved extracted features to image_vectors.npy\")\n"]},{"cell_type":"code","execution_count":6,"id":"e12efda8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e12efda8","executionInfo":{"status":"ok","timestamp":1742812354491,"user_tz":-420,"elapsed":141,"user":{"displayName":"Trí Minh Nguyễn","userId":"13730675261346438318"}},"outputId":"8f2b5105-4ad3-4294-972f-5fd9315c6cd7"},"outputs":[{"output_type":"stream","name":"stdout","text":["☁️ Uploaded image vectors to GCS: features/image_vectors.npy\n"]}],"source":["\n","vector_blob = bucket.blob(\"features/image_vectors.npy\")\n","vector_blob.upload_from_filename(\"/content/image_vectors.npy\")\n","print(\"☁️ Uploaded image vectors to GCS: features/image_vectors.npy\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"9LwqIrTWtZ0a"},"id":"9LwqIrTWtZ0a","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}