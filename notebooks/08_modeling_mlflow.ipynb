{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 08_modeling_mlflow.ipynb\n",
        "\n",
        "# 🧠 Emotion Recognition - Modeling with MLflow Tracking\n",
        "\n",
        "\"\"\"\n",
        "This notebook trains multiple machine learning models to classify facial emotions using the extracted image features.\n",
        "The training process includes:\n",
        "\n",
        "- ✅ Training a Random Forest (RF) model\n",
        "- ✅ Training a Deep Neural Network (DNN) using Keras\n",
        "- ✅ (Optional) Training XGBoost for comparison\n",
        "- ✅ Tracking all metrics, hyperparameters, and artifacts using MLflow\n",
        "- ✅ Saving models locally (.pkl, .h5) and exporting logs to JSON\n",
        "\n",
        "📦 Inputs:\n",
        "- `image_vectors.npy`: Extracted features from ResNet50 (saved in previous step)\n",
        "- `final_emotion_dataset.parquet`: Annotated labels (emotion, age, gender, etc.)\n",
        "\n",
        "📤 Output:\n",
        "- Trained models (locally and optionally to GCS)\n",
        "- `model_monitor_log.json`: Performance summary per model\n",
        "- MLflow logs (if local/remote MLflow server is connected)\n",
        "\n",
        "💡 This step is crucial for comparing modeling strategies and tracking experiments reliably.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "PGk0aF3MgB0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mlflow\n",
        "!pip install -q xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p85FewRZaHe7",
        "outputId": "785a5166-9aa2-4a92-821a-8af4d2159c3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.0/681.0 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 08_modeling_mlflow.ipynb\n",
        "\n",
        "# 🧠 Emotion Recognition - Modeling with MLflow Tracking\n",
        "\n",
        "# ✅ Import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "import xgboost as xgb\n",
        "import json\n",
        "import os\n"
      ],
      "metadata": {
        "id": "MJCujPfvZFdL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Load data\n",
        "from google.colab import auth\n",
        "from google.cloud import storage\n",
        "\n",
        "auth.authenticate_user()\n",
        "project_id = \"exalted-summer-454012-d2\"\n",
        "bucket_name = \"boothill2001-dataset\"\n",
        "\n",
        "# Load features\n",
        "client = storage.Client(project=project_id)\n",
        "bucket = client.bucket(bucket_name)\n",
        "bucket.blob(\"features/image_vectors.npy\").download_to_filename(\"image_vectors.npy\")\n",
        "bucket.blob(\"dataset/final_emotion_dataset.parquet\").download_to_filename(\"final_emotion_dataset.parquet\")"
      ],
      "metadata": {
        "id": "XAeMby_TZJFy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load(\"image_vectors.npy\")\n",
        "df = pd.read_parquet(\"final_emotion_dataset.parquet\")\n",
        "y = df['dominant_emotion']\n",
        "\n",
        "# ✅ Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# ✅ Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Start MLflow run\n",
        "mlflow.set_experiment(\"Emotion_Recognition\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7V9ykcVZJrG",
        "outputId": "6865c842-fd18-4050-af94-a4cd98abfa05"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/03/26 07:46:43 INFO mlflow.tracking.fluent: Experiment with name 'Emotion_Recognition' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='file:///content/mlruns/100354367244192138', creation_time=1742975203648, experiment_id='100354367244192138', last_update_time=1742975203648, lifecycle_stage='active', name='Emotion_Recognition', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Random Forest\n",
        "with mlflow.start_run(run_name=\"RandomForest\"):\n",
        "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    preds = rf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "\n",
        "    mlflow.log_param(\"model\", \"RandomForest\")\n",
        "    mlflow.log_param(\"n_estimators\", 100)\n",
        "    mlflow.log_metric(\"accuracy\", acc)\n",
        "    mlflow.sklearn.log_model(rf, \"rf_model\")\n",
        "\n",
        "    print(\"🔍 RF Accuracy:\", acc)\n",
        "\n",
        "# ✅ Deep Neural Network\n",
        "num_classes = len(np.unique(y_encoded))\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU-jMDEAZQcq",
        "outputId": "f0c08236-8311-4b79-dc47-5618565ae579"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/26 07:49:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 RF Accuracy: 0.24115148655025956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with mlflow.start_run(run_name=\"DNN\"):\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_shape=(X.shape[1],)),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train_cat, epochs=10, batch_size=64, validation_split=0.1, verbose=0)\n",
        "\n",
        "    loss, acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "    mlflow.log_param(\"model\", \"DNN\")\n",
        "    mlflow.log_metric(\"accuracy\", acc)\n",
        "    mlflow.keras.log_model(model, \"dnn_model\")\n",
        "\n",
        "    print(\"🔍 DNN Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7srwdRtZRCF",
        "outputId": "daf01d0c-8bc8-4fef-c0c9-616c75596dc3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "2025/03/26 07:51:41 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
            "\u001b[31m2025/03/26 07:51:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 DNN Accuracy: 0.24634261429309845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ XGBoost (optional)\n",
        "with mlflow.start_run(run_name=\"XGBoost\"):\n",
        "    xgb_model = xgb.XGBClassifier(n_estimators=100, max_depth=6, use_label_encoder=False, eval_metric='mlogloss')\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "    xgb_preds = xgb_model.predict(X_test)\n",
        "    xgb_acc = accuracy_score(y_test, xgb_preds)\n",
        "\n",
        "    mlflow.log_param(\"model\", \"XGBoost\")\n",
        "    mlflow.log_metric(\"accuracy\", xgb_acc)\n",
        "    mlflow.xgboost.log_model(xgb_model, \"xgb_model\")\n",
        "\n",
        "    print(\"🔍 XGBoost Accuracy:\", xgb_acc)\n",
        "\n",
        "# ✅ Save monitoring log\n",
        "model_log = {\n",
        "    \"RandomForest\": {\"accuracy\": float(acc)},\n",
        "    \"DNN\": {\"accuracy\": float(acc)},\n",
        "    \"XGBoost\": {\"accuracy\": float(xgb_acc)}\n",
        "}\n",
        "\n",
        "os.makedirs(\"monitoring\", exist_ok=True)\n",
        "with open(\"monitoring/model_monitor_log.json\", \"w\") as f:\n",
        "    json.dump(model_log, f, indent=2)\n",
        "\n",
        "print(\"✅ All models trained and logged to MLflow. Monitoring log saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7207R31ZbuC",
        "outputId": "c03e080f-8812-4e03-ef12-a35ccb77b7dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:52:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:06:09] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\u001b[31m2025/03/26 08:06:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 XGBoost Accuracy: 0.2298253893345918\n",
            "✅ All models trained and logged to MLflow. Monitoring log saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ GCS Upload Utility\n",
        "from google.cloud import storage\n",
        "\n",
        "def upload_model_to_gcs(local_path, gcs_path, bucket_name, project_id):\n",
        "    \"\"\"Uploads a local model file to GCS.\"\"\"\n",
        "    client = storage.Client(project=project_id)\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(gcs_path)\n",
        "    blob.upload_from_filename(local_path)\n",
        "    print(f\"✅ Uploaded {local_path} to gs://{bucket_name}/{gcs_path}\")\n",
        "\n",
        "# ✅ Example usage:\n",
        "# upload_model_to_gcs(\"random_forest.pkl\", \"models/random_forest.pkl\", bucket_name=\"boothill2001-dataset\", project_id=\"exalted-summer-454012-d2\")\n"
      ],
      "metadata": {
        "id": "ywNCViSOjaFl"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}